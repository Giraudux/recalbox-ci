name: nibble

on:
  workflow_call:
    inputs:
      tag:
        required: true
        type: string
      arch:
        required: true
        type: string
      timeout:
        type: number
        default: 16200 # 4.5 hours
      build_extra_args:
        type: string
        default: ""
      ccache_on:
        type: boolean
        default: true
      dl_upload_on:
        type: boolean
        default: true
    outputs:
      status:
        value: ${{ jobs.build.outputs.status }}

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.build.outputs.status }}
      dl_artifact_name: dl-${{ inputs.tag }}-${{ inputs.arch }}-${{ job.check_run_id }}
    steps:
    # Install dependencies
    - name: "Install dependencies"
      run: |
        set -x
        mkdir --parents "${{ runner.temp }}/dev/" "${{ runner.temp }}/ccache/" "${{ runner.temp }}/dl/"
        sudo apt update
        sudo apt install --yes zfsutils-linux qemu-utils tree
        sudo modprobe nbd nbds_max=2
        ln --symbolic /dev/nbd0 "${{ runner.temp }}/dev/disk0"
        ln --symbolic /dev/nbd1 "${{ runner.temp }}/dev/disk1"
    # Free disk space
    - name: "Free disk space"
      uses: endersonmenezes/free-disk-space@v3
      with:
        remove_android: true
        remove_dotnet: true
        remove_haskell: true
        remove_tool_cache: true
        remove_swap: true
        remove_packages: "azure-cli google-cloud-cli microsoft-edge-stable google-chrome-stable firefox postgresql* temurin-* *llvm* mysql* dotnet-sdk-*"
        remove_packages_one_command: true
        remove_folders: "/usr/share/swift /usr/share/miniconda /usr/share/az* /usr/local/lib/node_modules /usr/local/share/chromium /usr/local/share/powershell /usr/local/julia /usr/local/aws-cli /usr/local/aws-sam-cli /usr/share/gradle"
        rm_cmd: "rmz"
        rmz_version: "3.1.1"
        testing: false
    # Disk space available
    - name: "Available disk space"
      if: always()
      run: df --human-readable
    # Import zpool
    - name: "Download artifact disk 1"
      uses: actions/download-artifact@v5
      with:
        name: disk1-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2
        path: ${{ runner.temp }}
    - name: "Connect & import disk 1"
      run: |
        set -x
        sudo mv "${{ runner.temp }}/disk1-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2" /mnt/
        sudo qemu-nbd --connect "${{ runner.temp }}/dev/disk1" --format qcow2 "/mnt/disk1-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2"
        sudo zpool import -d "${{ runner.temp }}/dev/" disk1
        zfs get all disk1
    # Import docker image
    - name: "Download artifact Docker image"
      uses: actions/download-artifact@v5
      with:
        name: recalbox-${{ inputs.tag }}-${{ inputs.arch }}.tar.zst
        path: ${{ runner.temp }}
    - name: "Load Docker image"
      run: |
        zstdcat "${{ runner.temp }}/recalbox-${{ inputs.tag }}-${{ inputs.arch }}.tar.zst" | docker load
        rm "${{ runner.temp }}/recalbox-${{ inputs.tag }}-${{ inputs.arch }}.tar.zst"
    - name: "Download artifact disk 0"
      uses: actions/download-artifact@v5
      with:
        name: disk0-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2
        path: ${{ runner.temp }}
    - name: "Connect & import disk 0"
      run: |
        set -x
        sudo qemu-nbd --connect "${{ runner.temp }}/dev/disk0" --format qcow2 "${{ runner.temp }}/disk0-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2"
        sudo zpool import -d "${{ runner.temp }}/dev/" disk0
        zfs get all disk0
    # Cache
    - name: "Restore cache"
      if: inputs.ccache_on
      id: cache-ccache-restore
      uses: actions/cache/restore@v4
      with:
        key: ccache-${{ inputs.arch }}-${{ github.run_id }}-${{ job.check_run_id }}
        restore-keys: ccache-${{ inputs.arch }}
        path: ${{ runner.temp }}/ccache/
    # Build
    - name: "Build"
      id: build
      run: |
        set -x
        readonly timeout_sec="${{ inputs.timeout }}"
        current_time_sec=$(date +%s)
        end_time_sec=$((current_time_sec + timeout_sec))
        (sleep "$timeout_sec" ; docker exec --user root recalbox sh -c "chmod -x /usr/bin/make") &
        cd "/pool/disk0/recalbox/"
        if docker run --rm --security-opt seccomp=unconfined \
          --name recalbox \
          --volume "/pool/disk0/recalbox/:/work/" \
          --volume "/pool/disk1/output/:/work/output/" \
          --volume "/pool/disk1/.npm/:/.npm/" \
          --volume "${{ runner.temp }}/dl/:/share/dl/" \
          --volume "${{ runner.temp }}/ccache/:/share/ccache" \
          --env "ARCH=${{ inputs.arch }}" \
          --env "RECALBOX_VERSION=${{ inputs.tag }}" \
          --env "FORCE_UNSAFE_CONFIGURE=1" \
          --env "PACKAGE=BR2_BACKUP_SITE=\"${{ secrets.BR2_BACKUP_SITE }}\" ${{ inputs.build_extra_args }}" \
          --env "RECALBOX_CCACHE_ENABLED=${{ inputs.ccache_on && 'y' || '' }}" \
          --env "RECALBOX_CCACHE_MAX_SIZE=9G" \
          --user "$(id --user):$(id --group)" \
          recalbox
        then
          echo "status=success" >> "$GITHUB_OUTPUT"
          ls "/pool/"*/*/
        else
          current_time_sec=$(date +%s)
          if [ "$current_time_sec" -lt "$end_time_sec" ]
          then
            echo "status=failure" >> "$GITHUB_OUTPUT"
            exit 1
          else
            echo "status=continue" >> "$GITHUB_OUTPUT"
          fi
        fi
    - name: "Upload artifact images directory"
      if: steps.build.outputs.status == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: images-${{ inputs.tag }}-${{ inputs.arch }}
        path: /pool/disk0/output/images/
        compression-level: 0
    # Disk space available
    - name: "Available disk space"
      if: always()
      run: |
        set -x
        df --human-readable
        du -skh "/pool/"*/*/
    # Cache
    - name: "Clear cache"
      if: always() && inputs.ccache_on
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        set -x
        cache_keys=$(gh cache list --repo "${{ github.repository }}" --key "ccache-${{ inputs.arch }}" --json id --jq ".[].id")
        for cache_key in $cache_keys
        do
            gh cache delete --repo "${{ github.repository }}" "$cache_key" || true
        done
    - name: "Save cache"
      id: cache-ccache-save
      if: always() && inputs.ccache_on
      uses: actions/cache/save@v4
      with:
        key: ${{ steps.cache-ccache-restore.outputs.cache-primary-key }}
        path: ${{ runner.temp }}/ccache/
    # Export zpool
    - name: "Export & disconnect disk 0"
      id: export-zpool-disk0
      if: always()
      run: |
        set -x
        zfs get all disk0
        sudo zpool export disk0
        sudo qemu-nbd --disconnect "${{ runner.temp }}/dev/disk0"
    - name: "Export & disconnect disk 1"
      id: export-zpool-disk1
      if: always()
      run: |
        set -x
        zfs get all disk1
        sudo zpool export disk1
        sudo qemu-nbd --disconnect "${{ runner.temp }}/dev/disk1"
    - name: "Upload artifact dl directory"
      if: always() && inputs.dl_upload_on
      uses: actions/upload-artifact@v4
      with:
        name: dl-${{ inputs.tag }}-${{ inputs.arch }}-${{ job.check_run_id }}
        path: ${{ runner.temp }}/dl/
    - name: "Upload artifact disk 0"
      if: always() && steps.export-zpool-disk0.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: disk0-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2
        path: ${{ runner.temp }}/disk0-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2
        compression-level: 0
        overwrite: true
    - name: "Upload artifact disk 1"
      if: always() && steps.export-zpool-disk1.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: disk1-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2
        path: /mnt/disk1-${{ inputs.tag }}-${{ inputs.arch }}.zpool.qcow2
        compression-level: 0
        overwrite: true
